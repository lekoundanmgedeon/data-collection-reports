{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLdljxft6EW7"
   },
   "source": [
    "## **LEKOUNDA NGOLO** Mardochet Gedeon\n",
    "### COOP MSC | **DATA SCIENCE**\n",
    "### ASSIGNMENT 4 : DATA COLLECTION\n",
    "#### 29-111-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'red'> Disclaimer : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Mr Abdoul W. , si vous voyez ce code et remarquez quelques elements vides, sachez que je n'ai pas pu recuperer les données tel qu'il le soit avec le  css selector de selenium (montré en classe) car au moment où je travaillais il y'avait aussi d'autres etudiants comme moi qui faisait la meme chose cela fait que le site ne repondais pas à de certains moment. Je me suis permis d'utiliser certaines alternives qui fonctionnerais pour les besoins de test et qui ont toute fois posez des problemes lors de la recuperations des données. C'est pour cela que vous pouvez remarqué quelques elements manquant (c'est due au navigateur et à la connexion internet) \n",
    "\n",
    "Mais je vous assure que le code en soi est propre, coherent et fonctionnel j'ai pris le soin de le testé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "j67veSSy_lN1"
   },
   "outputs": [],
   "source": [
    "url = 'https://ci.coinafrique.com/categorie/appartements?page=13'\n",
    "# scrape data (number of rooms, number of bathroom, area, price, location, image_link) over 200 pages\n",
    "# using selenium combined with BeautifulSoup\n",
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oc1cp0im-IY"
   },
   "outputs": [],
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DTKy31-E6CYt"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4FFvJK6NAWZ9"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 671
    },
    "id": "Srnf2ks6752Z",
    "outputId": "c58582d3-0172-4a74-9a9e-db316bd9dfcc"
   },
   "outputs": [],
   "source": [
    "# instantiate a Chrome options object\n",
    "options = webdriver.ChromeOptions()\n",
    "# set the options to use Chrome in headless mode (used for running the script in the background)\n",
    "options.add_argument(\"--headless=new\")\n",
    "# initialize an instance of the Chrome driver (browser) in headless mode\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "L5KkDDPuAVHO"
   },
   "outputs": [],
   "source": [
    "base_url = \"https://ci.coinafrique.com/categorie/appartements?page=\"\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1588865b240>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import sqlite3\n",
    "import sqlite3\n",
    "# Create a connection with a database (renting_rooms.db)\n",
    "conn = sqlite3.connect('scrapped_pages.db')\n",
    "# create a cursor (allows to interact with the database)\n",
    "c = conn.cursor()\n",
    "# create a table\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS RR_table(title,price,location,rooms,bathrooms,url,image_link)''')\n",
    "## 'CREATE IF NOT EXISTS...' : Pour eviter les erreur quand je reexecute encore la cellule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://ci.coinafrique.com/categorie/appartements?page=12'\n",
    "driver.get(url)\n",
    "soup = bs(driver.page_source, \"html.parser\")\n",
    "containers = soup.select(\"div.card.ad__card\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3XxZ6SvAuUJ"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "\n",
    "def scrape_page(page_number):\n",
    "    url = f'https://ci.coinafrique.com/categorie/appartements?page={page_number}'\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = bs(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # REAL CSS CLASS FOR EACH AD PREVIEW\n",
    "    containers = driver.find_elements(By.CSS_SELECTOR,\"[class='col s6 m4 l3']\")\n",
    "    containers = soup.select(\"div.card.ad__card\") ## Temporary test\n",
    "    # I Use soup.select to bypass driver.find (selenium function) error with my browser\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for container in containers:\n",
    "        try:\n",
    "            # Extract product link\n",
    "            a_tag = container.find(\"a\", href=True)\n",
    "            if not a_tag:\n",
    "                continue\n",
    "\n",
    "            product_url = \"https://ci.coinafrique.com\" + a_tag[\"href\"]\n",
    "\n",
    "            # Open detailed page\n",
    "            driver.get(product_url)\n",
    "            time.sleep(2)\n",
    "            ## Mr ABDUL W. time.sleep(2) ceci est extremement necessaire pour les requetes \n",
    "            ## en effet ici on donne un delais de 2s pour chaque requetes, cela permettra de \n",
    "            ## recuperer un maximum nombre de page ainsi evitera de surcharger le serveur\n",
    "            soup_detail = bs(driver.page_source, \"html.parser\")\n",
    "\n",
    "            # Title\n",
    "            title_tag = soup_detail.find(\"h1\")\n",
    "            title = title_tag.get_text(strip=True) if title_tag else None\n",
    "            # On revoie None comme valeur par defaut dans le cas ou on arrive pas a recuperer le titer\n",
    "            # Price\n",
    "            price_tag = soup_detail.find(\"p\", class_=\"ad__price\")\n",
    "            if not price_tag:\n",
    "                price_tag = soup_detail.find(\"span\", class_=\"price\")\n",
    "\n",
    "            if price_tag:\n",
    "                price_raw = price_tag.get_text(strip=True)\n",
    "                price = price_raw.replace(\"CFA\", \"\").replace(\" \", \"\")\n",
    "            else:\n",
    "                price = None\n",
    "\n",
    "            # full adress\n",
    "            loc_tag = soup_detail.find(\"p\", class_=\"ad__card-location\")\n",
    "            if loc_tag:\n",
    "                location = loc_tag.get_text(strip=True)\n",
    "            else:\n",
    "                # backup\n",
    "                loc2 = soup_detail.find(\"span\", class_=\"location\")\n",
    "                location = loc2.get_text(strip=True) if loc2 else None\n",
    "\n",
    "            # Extract Rooms / Bathrooms\n",
    "            rooms = None\n",
    "            bathrooms = None\n",
    "\n",
    "            info_list = soup_detail.find_all(\"li\", class_=\"center\")\n",
    "\n",
    "            for li in info_list:\n",
    "                label = li.find_all(\"span\")\n",
    "                if len(label) >= 2:\n",
    "                    name = label[0].get_text(strip=True).lower()\n",
    "                    qt = label[1].get_text(strip=True)\n",
    "\n",
    "                    if \"pièces\" in name:\n",
    "                        rooms = qt\n",
    "                    elif \"bain\" in name:\n",
    "                        bathrooms = qt\n",
    "            # Extract first main image\n",
    "            img_tag = soup_detail.find(\"img\")\n",
    "            image_link = img_tag[\"src\"] if img_tag else None\n",
    "\n",
    "            data.append({\n",
    "                \"title\": title,\n",
    "                \"price\": price,\n",
    "                \"location\": location,\n",
    "                \"rooms\": rooms,\n",
    "                \"bathrooms\": bathrooms,\n",
    "                \"image\": image_link,\n",
    "                \"url\": product_url\n",
    "            })\n",
    "            # or load it in database\n",
    "            # add data to RR_table from renting_rooms.db\n",
    "            c.execute('''INSERT INTO RR_table VALUES(?,?,?,?,?,?,?)''',(title,price,location,rooms,bathrooms,url,image_link ))\n",
    "            # commit the request \n",
    "            conn.commit()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error on item:\", e)\n",
    "            continue\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = [] # liste vide \n",
    "\n",
    "for page in range(1,3):\n",
    "    print(f\"Scraping page {page}\")\n",
    "    page_data = scrape_page(page)\n",
    "    datas.extend(page_data)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame(datas)\n",
    "print(df.head())\n",
    "print(\"Nombre total d'entrées:\", len(df))\n",
    "\n",
    "#df.to_csv(\"coinafrique_apartments_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the table from scrapped_pages.db\n",
    "df = pd.read_sql_query('select * from RR_table', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price here is object i want keep it in float\n",
    "df[\"price\"] = (\n",
    "    df[\"price\"]\n",
    "    .str.replace(\"FCFA\", \"\", regex=False)\n",
    "    .str.replace(\" \", \"\")\n",
    "    .str.extract(r\"(\\d+)\")\n",
    ")\n",
    "df[\"price\"] = df[\"price\"].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean rooms and bathrooms\n",
    "df[\"rooms\"] = df[\"rooms\"].str.extract(r\"(\\d+)\").astype(\"int64\")\n",
    "df[\"bathrooms\"] = df[\"bathrooms\"].str.extract(r\"(\\d+)\").astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "df.to_csv(\"coinafrique_appartements.csv\", index=False)\n",
    "print(\"Saved coinafrique_appartements.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "daily-notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
